#!/usr/bin/env python3

import argparse
import atexit
import csv
import os
import shutil
import string
import subprocess
import sys
import tempfile

HELP='''
csv_input is a CSV file, whose first line defines the column names.
parquet_output is the Parquet output (i.e., directory in which one or more
    Parquet files are written.)

For tab-separated values, pass --delimiter='\t', or other value as appropriate.
'''.strip()

# True iff we are to preserve temporary files.
# Globally set to true in debug mode.
global preserve
preserve = False

parser = argparse.ArgumentParser()
parser.add_argument('csv_input',
                    help='Path to input CSV file')
parser.add_argument('parquet_output',
                    help='Path to Parquet output')
parser.add_argument('--delimiter', default=',',
                    help='Input field delimiter. Set to "\t" for tab-separated values, for example')
parser.add_argument('--debug', default=False, action='store_true',
                    help='Preserve intermediate files and logs')

DRILL_OVERRIDE_TEMPLATE = '''
drill.exec: {
  sys.store.provider: {
    # The following section is only required by LocalPStoreProvider
    local: {
      path: "${local_base}",
      write: true
    }
  },
  tmp: {
    directories: ["${local_base}"],
    filesystem: "drill-local:///"
  },
  sort: {
    purge.threshold : 100,
    external: {
      batch.size : 4000,
      spill: {
        batch.size : 4000,
        group.size : 100,
        threshold : 200,
        directories : [ "${local_base}/spill" ],
        fs : "file:///"
      }
    }
  },
}
'''

class CsvSource:
    def __init__(self, path: str, delimiter: str):
        self.path = path
        self.delimiter = delimiter
        self._headers = None
    @property
    def headers(self):
        if self._headers is None:
            with open(self.path, newline='') as handle:
                csv_data = csv.reader(handle, delimiter=self.delimiter)
                self._headers = next(csv_data)
        return self._headers

class TempLocation:
    _tempdir = None
    def __init__(self):
        drive, path = os.path.splitdrive(self.tempdir)
        assert drive == '', 'Windows support not provided yet'
        assert path.startswith('/tmp/'), self.tempdir
        self.dfs_tmp_base = path[len('/tmp'):]
    def dfs_tmp_path(self, path: str):
        return os.path.join(self.dfs_tmp_base, path)
    def full_path(self, path: str):
        return os.path.join(self.tempdir, path)
    @property
    def tempdir(self):
        if self._tempdir is None:
            self._tempdir = tempfile.mkdtemp(prefix='/tmp/')
            if preserve:
                print('Preserving logs and intermediate files: ' + self._tempdir)
            else:
                atexit.register(shutil.rmtree, self._tempdir)
        return self._tempdir

class DrillInstallation:
    '''Create a temporary, custom Drill installation
    
    Even in embedded mode, Drill runs in a stateful fashion, storing
    its state in (by default) /tmp/drill. This poses a few problems
    for running csv2parquet in ways that are (a) robust, and (b)
    certain not to affect any other Drill users, human or machine.

    This would be an easy problem to solve if I could create a custom
    conf/drill-overrides.conf, and pass it to drill-embedded as a
    command line option. However, as of Drill 1.4, the only way to do
    such customization is to modify the actual drill-overrides.conf
    file itself, before starting drill-embedded.

    This class gets around this through an admittedly unorthodox hack:
    creating a whole parallel Drill installation under a temporary
    directory, with a customized conf/ directory, but reusing (via
    symlinks) everything else in the main installation. This lets us
    safely construct our own drill configuration, using its own
    separate equivalent of /tmp/drill (etc.), and which is all cleaned
    up after the script exits.

    (Feature request to anyone on the Drill team reading this: Please
    give drill-embedded a --with-override-file option!)

    '''
    def __init__(self, reference_executable:str=None):
        self.location = TempLocation()
        if reference_executable is None:
            reference_executable = shutil.which('drill-embedded')
        assert reference_executable is not None
        self.reference_executable = reference_executable
        self.reference_base, self.bindir = os.path.split(os.path.dirname(reference_executable))
        self.install()
    @property
    def base(self):
        return os.path.join(self.location.tempdir, 'drill')
    @property
    def local_base(self):
        return os.path.join(self.location.tempdir, 'drill-local-base')
    @property
    def executable(self):
        return os.path.join(self.base, self.bindir, 'drill-embedded')
    def install(self):
        # create required subdirs
        for dirname in (self.base, self.local_base):
            os.makedirs(dirname)
        # link to reference
        for item in os.scandir(self.reference_base):
            if item.name == 'conf':
                assert item.is_dir()
                continue
            os.link(item.path, os.path.join(self.base, item.name))
        # install config
        conf_dir = os.path.join(self.base, 'conf')
        os.makedirs(conf_dir)
        with open(os.path.join(conf_dir, 'drill-override.conf'), 'w') as handle:
            handle.write(string.Template(DRILL_OVERRIDE_TEMPLATE).substitute(
                local_base=self.local_base))

    def build_script(self, csv_source: CsvSource, parquet_output: str):
        return DrillScript(self, csv_source, parquet_output)
        
class DrillScript:
    def __init__(self, drill: DrillInstallation, csv_source: CsvSource, parquet_output: str):
        self.drill = drill
        self.csv_source = csv_source
        self.parquet_output = parquet_output
    def render(self):
        script = '''alter session set `store.format`='parquet';
CREATE TABLE dfs.tmp.`{}` AS
SELECT
'''.format(self.drill.location.dfs_tmp_path('parquet_tmp_output'))
        column_lines = ['columns[{}] as `{}`'.format(n, header)
                        for n, header in enumerate(self.csv_source.headers, 1)]
        script += ',\n'.join(column_lines) + '\n'
        script += 'FROM dfs.`{}`\n'.format(self.csv_source.path)
        script += 'OFFSET 1\n'
        return script
    def run(self):
        # execute drill script
        script_path = os.path.join(self.drill.location.tempdir, 'script')
        script_stdout = os.path.join(self.drill.location.tempdir, 'script_stdout')
        script_stderr = os.path.join(self.drill.location.tempdir, 'script_stderr')
        cmd = [
            self.drill.executable,
            '--run={}'.format(script_path),
        ]
        with open(script_path, 'w') as handle:
            handle.write(self.render())
        with open(script_stdout, 'w') as stdout, open(script_stderr, 'w') as stderr:
            proc = subprocess.Popen(cmd, stdout=stdout, stderr=stderr)
            proc.wait()
        assert proc.returncode == 0, proc.returncode
        # publish resulting output parquet file
        os.rename(self.drill.location.full_path('parquet_tmp_output'), self.parquet_output)
        

if __name__ == "__main__":
    args = parser.parse_args()
    if args.debug:
        preserve = True
    # Quick pre-check whether destination exists. There's a race
    # condition because it can still be created between now and when
    # we eventually try to write it, but this will catch the common case.
    if os.path.exists(args.parquet_output):
        sys.stderr.write('Output location "{}" already exists. Rename or delete before running again.\n'.format(args.parquet_output))
        sys.exit(1)
    csv_source = CsvSource(args.csv_input, args.delimiter)
    drill = DrillInstallation()
    drill_script = drill.build_script(csv_source, args.parquet_output)
    drill_script.run()
